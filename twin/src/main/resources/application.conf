## akka cluster

akka {
  loglevel = "DEBUG"

  actor {
    provider = "cluster"

    allow-java-serialization = on # for inter node communication, maybe other serializer because of performance issues (screenshot)

    #serialization-bindings {
    #  "sample.killrweather.CborSerializable" = jackson-cbor  // also good for persistence
    #}

  }
  #actor.provider = "cluster"

  coordinated-shutdown.exit-jvm = on

  cluster {
    shutdown-after-unsuccessful-join-seed-nodes = 60s

    sharding {
      number-of-shards = 100  # sharding
    }

    downing-provider-class = "akka.cluster.sbr.SplitBrainResolverProvider"  # sharding
    
  }

  # to test event sourcing
  persistence {
    ## inmem only for tests # in memory stored not in database
    #journal.plugin = "akka.persistence.journal.inmem"
    ##snapshot-store.plugin = "akka.persistence.snapshot-store.local"
    ##snapshot-store.local.dir = "target/snapshot"

    journal {
      plugin = "jdbc-journal"
      auto-start-journals = ["jdbc-journal"]

    }

    #snapshot-store {
    #  plugin = "jdbc-snapshot-store"
    #}

  }

  projection { 
    recovery-strategy {
      strategy = retry-and-fail
      retries = 5
      retry-delay = 1 s
    }
    restart-backoff {
      min-backoff = 5s
      max-backoff = 30s
      random-factor = 0.2
    }
    jdbc {
      dialect = "postgres-dialect"

      blocking-jdbc-dispatcher {
        type = Dispatcher
        executor = "thread-pool-executor"
        thread-pool-executor {
          # Use same number of threads as connections in the JDBC connection pool.
          fixed-pool-size = 10  # see woe.twin.sql.max-pool-size
          # TODO waiting for bug fix - fixed-pool-size = ${?device_projection_jdbc_pool_size}
        }
        throughput = 1
      }

      offset-store {
        schema = ""
        table = "akka_projection_offset_store" # tables need to be defined on readside DB for projections to work
        management-table = "akka_projection_management"
      }
    }
    
  }

}
jdbc-journal {
  slick = ${slick}
  #slick = ${slick}
}

slick {
  profile = "slick.jdbc.PostgresProfile$"
  db {
    host = "localhost"
    url = "jdbc:postgresql://"${slick.db.host}":5432/docker?reWriteBatchedInserts=true"
    url = ${?postgresql_url}"?reWriteBatchedInserts=true"
    user = "changeme"
    user = ${?postgresql_username}
    password = "changeme"
    password = ${?postgresql_password}
    driver = "org.postgresql.Driver"
    numThreads = 10
    maxConnections = 10
    minConnections = 1
  }
}

# read side cqrs, This is only used for akka persistence query? the akka-persistence-query provider in use? Akka Microservices exampe
jdbc-read-journal { # need to read the events from event journal of course?
  slick = ${slick} 
}

slick_read_side { # this is needed to write in projections to readside db
  profile = "slick.jdbc.PostgresProfile$"
  db {
    host = "localhost"
    url = "jdbc:postgresql://"${slick.db.host}":5432/docker?reWriteBatchedInserts=true"
    url = ${?postgresql_url_readside}"?reWriteBatchedInserts=true"
    user = "changeme"
    user = ${?postgresql_username_readside}
    password = "changeme"
    password = ${?postgresql_password_readside}
    driver = "org.postgresql.Driver"
    numThreads = 10
    maxConnections = 10
    minConnections = 1
  }
}

# the akka-persistence-snapshot-store in use
#jdbc-snapshot-store {
#  slick = ${slick}
#}

#management-config
akka.management {
  cluster.bootstrap {
    contact-point-discovery {
      # pick the discovery method you'd like to use:
      discovery-method = kubernetes-api

      required-contact-point-nr = ${REQUIRED_CONTACT_POINT_NR}
    }
  }
}
#management-config


akka.management {
  # match Kubernetes Health checks
  # https://doc.akka.io/docs/akka-management/current/healthchecks.html
  health-checks {
    # Readiness checks: should the application receive external traffic
    readiness-checks {
      ready = "twin.HealthCheck"
      #example-ready = "twin.HealthCheck"
    }
    #  Liveness checks: should the application be left running
  }
}

## akka cluster 

# for interaction with db in projections etc
scalikejdbc.global {
  loggingSQLErrors = true
  loggingConnections = false
}

# These settings configure the database connection for ScalikeJDBC and the akka-persistence-jdbc plugin
jdbc-connection-settings {
  driver = "org.postgresql.Driver"

  # the following properties must be filled with the production values
  # they can be set using -D arguments, eg: -jdbc-connection-settings.user=the-production-user
  url = ${slick_read_side.db.url}
  user = ${slick_read_side.db.user}
  password = ${slick_read_side.db.password}


  # the following properties are used to configure the
  # Hikari connection pool used on the read-side (akka-projections)
  connection-pool {
    # How many connections should be available to from the pool?
    # it's recommended to use the same value used by the blocking-jdbc-dispatcher (see above)
    max-pool-size = ${akka.projection.jdbc.blocking-jdbc-dispatcher.thread-pool-executor.fixed-pool-size}

    # How long should we wait (in millis) before it times out?
    # In a normal scenario, we should always be able to get a connection
    # If we got a thread from the blocking-jdbc-dispatcher, we should be able to get a connection.
    # If for some reason the pool can't provide a connection, it's better to let it crash and liberate the current thread.
    # Hence the low timout (note, 250 is lowest value hikari accepts)
    timeout = 250ms
  }
}

simulator {
  port = "31123" # as configured in simulators external service
  host = "192.168.49.2" # this is the minikube cluster ip
}

readside {
  host = ${?READSIDE_INTERNAL_SERVICE_SERVICE_HOST} #env variables from K8s
  port = ${?READSIDE_INTERNAL_SERVICE_SERVICE_PORT}
}